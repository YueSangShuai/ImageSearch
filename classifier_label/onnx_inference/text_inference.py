import time
from transformers import AutoTokenizer
import onnxruntime as ort
import numpy as np

# é…ç½®
device = "cpu"  # æˆ– "cpu"
texts = ["Hello world 666."]
onnx_path = "/data/yuesang/LLM/VectorIE/siglip2_text_encoder.onnx"
model_path = "/data/yuesang/LLM/VectorIE/models/mexma-siglip2"

# åŠ è½½ tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True, trust_remote_code=True)

# ç¼–ç è¾“å…¥
inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='np')
print(inputs)

# åˆ›å»º ONNX æ¨ç†ä¼šè¯ï¼ˆæŒ‡å®šä½¿ç”¨ CUDA æˆ– CPUï¼‰
providers = ['CUDAExecutionProvider'] if device == "cuda" else ['CPUExecutionProvider']
session = ort.InferenceSession(onnx_path, providers=providers)

# è·å–è¾“å…¥è¾“å‡ºå
input_names = [i.name for i in session.get_inputs()]
output_names = [o.name for o in session.get_outputs()]


onnx_inputs = {name: inputs[name] for name in input_names}
output = session.run(output_names, onnx_inputs)

print(output)
# from sklearn.metrics.pairwise import cosine_similarity
# vectors = []
# with open("/data/yuesang/LLM/VectorIE/c++/build/output.txt", "r") as f:
#     for line in f:
#         vec = np.array([float(x) for x in line.strip().split()])
#         vectors.append(vec)

# vectors = np.stack(vectors).reshape(output[0].shape)


# vec1 = vectors.reshape(-1, vectors.shape[-1])     # æ¥è‡ª C++
# vec2 = output[0].reshape(-1, output[0].shape[-1]) # æ¥è‡ª Python

# print(vec1.shape)
# print(vec2.shape)

# æ¯”è¾ƒæ¯ä¸€å¯¹å‘é‡
# similarities = cosine_similarity(vec1, vec2)

# print("ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µï¼š")
# print(similarities)
# print(output[0])
# print(similarities)
# print(vectors.shape)
# print(output[0].shape)

# warn_up_range=50
# test_range=500
# from tqdm import tqdm
# # === é¢„çƒ­ ===
# for _ in tqdm(range(warn_up_range)):
#     _ = session.run(output_names, onnx_inputs)

# # === æ­£å¼è®¡æ—¶ ===
# start = time.time()
# for _ in tqdm(range(test_range)):
#     _ = session.run(output_names, onnx_inputs)
# end = time.time()

# avg_time = (end - start) / test_range
# print(f"ğŸŒ¡ï¸ å¹³å‡æ¨ç†è€—æ—¶: {avg_time*1000:.2f} ms/æ¬¡")

# # è¾“å‡ºä¸€æ¡ embedding çœ‹çœ‹
# outputs = session.run(output_names, onnx_inputs)
# embeddings = outputs[0]
# # print("Embedding shape:", embeddings.shape)
# # print("First sentence embedding:", embeddings[0])
